---
title: "Home Prices EDA and Machine Learning"
output: html_document
---

```{r setup, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Add Libraries
```{r, include=FALSE}
library(data.table)
library(ggplot2)
library(ggthemes)
library(glmnet)
library(plotly)
library(MASS)
library(caret)
library(leaps)
theme_set(theme_bw())
```

#### Load in dataset
```{r}
#Price <- fread("trainPrice.csv")
Price <- fread("/Users/paulademacker/Documents/USA/Boston U/2. term/BA810/Team Project/trainPrice.csv")
```

#### First few rows
We can see that we have a total of 25 features in the dataset
```{r}
head(Price, 5)
```

#### Structure of the dataset
There are a total of 1,601,458 observations
```{r}
str(Price)
```


### Cleaning the Data

#### view the count of null values in each column
The feature, total_parking_capacity_in_site has the largest number of null values (91813)
```{r}
Price[, lapply(.SD, function(x) sum(is.na(x)))]
```
#### View all unqiue values present in columns
```{r}
unique(Price$heat_type)
```
##### How many are empty strings?
```{r}
Price[heat_type == ''][, .N]
```
##### We can remove these empty string values to create dummy variables later
```{r}
Price <- Price[heat_type != '']
```


```{r}
Price[heat_fuel == ''][, .N]
```


```{r}
Price[heat_fuel == '-'][, .N]
```
##### We can remove these empty string values to create dummy variables later
```{r}
Price <- Price[heat_fuel != '']
```

##### We can remove these empty string values to create dummy variables later
```{r}
Price <- Price[heat_fuel != '-']
```

```{r}
unique(Price$bathroom_count)
```
```{r}
unique(Price$city)
```
```{r}
unique(Price$room_count)
```
```{r}
unique(Price$front_door_structure)
```
```{r}
Price[front_door_structure == '-'][, .N]
```
##### count of values that are empty strings
```{r}
Price[front_door_structure == ''][, .N]
```
##### We can remove these empty string values to create dummy variables later
```{r}
Price <- Price[front_door_structure != '']
```
##### We can remove these empty dash values to create dummy variables later
```{r}
Price <- Price[front_door_structure != '-']
```

```{r}
unique(Price$year_of_completion)
```

#### Remove all rows that have missing values
There are a total of 1601458 million observations, and we will be removing less than 100,000 of them.
We can confirm that rows were removed using .N (the number of observations)
```{r}
Price <- na.omit(Price)
Price[, .N]
```

#### Set city and room count as factor
```{r}
Price <- Price[, city:=as.factor(city)]
Price <- Price[, room_count:=as.factor(room_count)]
Price <- Price[, bathroom_count:=as.factor(bathroom_count)]
#Price <- Price[, transaction_year_month := as.POSIXct(transaction_year_month, format='%Y%m')]
#Price <- Price[, year_of_completion := as.Date(year_of_completion, format='%Y')]

str(Price)
```


##### We can create dummy variables and convert them to factors
```{r}
Price <- fastDummies::dummy_cols(Price, select_columns = c("heat_fuel","heat_type","front_door_structure"))

Price <- Price[, heat_fuel_cogeneration:=as.factor(heat_fuel_cogeneration)]
Price <- Price[, heat_fuel_gas :=as.factor(heat_fuel_gas)]
Price <- Price[, heat_type_central:=as.factor(heat_type_central)]
Price <- Price[, heat_type_district:=as.factor(heat_type_district)]
Price <- Price[, heat_type_individual:=as.factor(heat_type_individual)]
Price <- Price[, front_door_structure_corridor:=as.factor(front_door_structure_corridor)]
Price <- Price[, front_door_structure_mixed:=as.factor(front_door_structure_mixed)]
Price <- Price[, front_door_structure_stairway:=as.factor(front_door_structure_stairway)]


```













#### Barchart showing real price and city
```{r}
ggplot(Price, aes(x=city, y = transaction_real_price)) + 
  geom_bar(stat = "summary", fun = "mean")+
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE)) +
  theme_classic()
```

#### Barchart showing real price and room count
```{r}
ggplot(Price, aes(x=room_count, y = transaction_real_price)) + 
  geom_bar(stat = "summary", fun = "mean")+
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE)) +
  theme_classic()
```
#### Barchart showing real price and front_door_structure
```{r}
ggplot(Price, aes(x=front_door_structure, y = transaction_real_price)) + 
  geom_bar(stat = "summary", fun = "mean")+
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE)) +
  theme_classic()
```

#### Barchart showing real price and heat_fuel
```{r}
ggplot(Price, aes(x=heat_fuel, y = transaction_real_price)) + 
  geom_bar(stat = "summary", fun = "mean")+
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE)) +
  theme_classic()
```
#### Barchart showing real price and heat_type
```{r}
ggplot(Price, aes(x=heat_type, y = transaction_real_price)) + 
  geom_bar(stat = "summary", fun = "mean")+
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE)) +
  theme_classic()
```





####Plotly Map showing locations of apartments
Still working on getting colors to appear for prices
```{r}
fig <- head(Price, 100000)
fig <- fig %>%
  plot_ly(
    lat = ~latitude,
    lon = ~longitude,
    #marker = list(color = "fuchsia"),
    color = Price[,"transaction_real_price"],
    type = 'scattermapbox',
    hovertext = Price[,"transaction_real_price"]) 
fig <- fig %>%
  layout(
    mapbox = list(
      style = 'open-street-map',
      zoom =2.5,
      center = list(longitude = 35.963911, latitude = 127.919770))) 

fig
```











## Linear Regression
#### Randomize the rows
```{r}
set.seed(42)
rows <- sample(nrow(Price))
Price <- Price[rows, ]
```


#### Linear model of price and city (the first 50000 observations)
```{r}
ggplot(head(Price, 50000), aes(x = city
, y=transaction_real_price)) +
  geom_point(alpha = 0.4)+
  stat_smooth(
    method = "lm",
    color = "#C42126",
    se = FALSE,
    size = 1
  )
```



#### Linear regression model of exclusive use area vs real price
```{r}
ggplot(Price, aes(x = exclusive_use_area, y=transaction_real_price)) +
  geom_point(alpha = 0.4)
```









# Linear Regression
```{r}
Price[, transaction_real_price := as.numeric(transaction_real_price)]


# we want to select random columns adn set the seed to get consistant results
set.seed(810)

# select random number
rnorm(1)



# Split tha data
# assign 100K random rows to the test set
# test index is a random set of 320000 numbers
# this way we can do an 80/20 split
test_index <- sample(nrow(Price), 320000)
# now split
# we use that set of random numbers to select those random rows
dd.test <- Price[test_index,]
dd.train <- Price[-test_index,]


# our response variables to use later
y.train <- dd.train$transaction_real_price
y.test <- dd.test$transaction_real_price



# create our predictors
f1 <- as.formula(transaction_real_price ~ front_door_structure_stairway)

# matrix with x values
x1.train.sample <- model.matrix(f1, dd.train)
x1.test <- model.matrix(f1, dd.test)

# get columns (for forward regression later)
#for (col in names(Price))
#{
 
 # print(col) 
  
#}


fit.lm1 <- lm(f1, dd.train)


yhat.train.lm1 <- predict(fit.lm1)
mse.train.lm1 <- mean((y.train - yhat.train.lm1)^2)
mse.train.lm1

yhat.test.lm1 <- predict(fit.lm1, dd.test)
mse.test.lm1 <- mean((y.test - yhat.test.lm1)**2)
mse.test.lm1


str(dd.train)



(y.test[0] - yhat.test.lm1[0])


class(Price$transaction_real_price)
```
### Ridge Regression
```{r}
fit.ridge <- cv.glmnet(x1.train.sample, y.train, alpha = 0)

predict(fit.ridge,
        type = "coefficients",
        s = fit.ridge$lambda)

to_plot <- data.table(
  lambda = fit.ridge$lambda,
  coef_value = ridge.coef[2, ]
)
ggplot(to_plot, aes(log(lambda), coef_value)) +
  geom_line() +
  theme_few()

yhat.train.ridge <- predict(fit.ridge, x1.train.sample, s = fit.ridge$lambda.min)
mse.train.ridge <- mean((y.train - yhat.train.ridge)^2)

yhat.test.ridge <- predict(fit.ridge, x1.test.sample, s = fit.ridge$lambda.min)
mse.test.ridge <- mean((y.test - yhat.test.ridge)^2)

print(mse.train.ridge)
print(mse.test.ridge)
```

#### Lasso Regression
```{r}
fit.lasso <- cv.glmnet(x1.train.sample, y.train, alpha = 1)

predict(fit.lasso,
        type = "coefficients",
        s = fit.lasso$lambda)

to_plot <- data.table(
  lambda = fit.lasso$lambda,
  coef_value = lasso.coef[2, ]
)
ggplot(to_plot, aes(log(lambda), coef_value)) +
  geom_line() +
  theme_few()

yhat.train.lasso <- predict(fit.lasso, x1.train.sample, s = fit.lasso$lambda.min)
mse.train.lasso <- mean((y.train.sample - yhat.train.lasso)^2)

yhat.test.lasso <- predict(fit.lasso, x1.test.sample, s = fit.lasso$lambda.min)
mse.test.lasso <- mean((y.test.sample - yhat.test.lasso)^2)

print(mse.train.lasso)
print(mse.test.lasso)
```










































